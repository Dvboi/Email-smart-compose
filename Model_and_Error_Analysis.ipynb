{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model & Error Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Results table (from all previous observations)"
      ],
      "metadata": {
        "id": "ww0tMHVyqYDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "x = PrettyTable()\n",
        "x.field_names = ['Embeddings','Model','# Params','Bleu-Score','Mean-latency (in ms)','90P-latency (in ms)','99P-latency (in ms)']\n",
        "x.add_row(['Glove word-embeddings(largest available)','LSTM Enc-dec','9.2M {1.5M trainable}',0.10,48.22,84.19,131.04])\n",
        "x.add_row(['Sentence-piece','T5 (Base)','220M',0.07,882.76, 1364.36, 2461.01])\n",
        "x.add_row(['Byte-Pair embeddings','GPT-2 (Base)','124M',0.18,11882.10,19693.22,21115.62])\n",
        "\n",
        "print(x)"
      ],
      "metadata": {
        "id": "ZSdcG__LqYhH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5961f58d-137d-4d27-8e03-af86bdd66002"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------+--------------+-----------------------+------------+----------------------+---------------------+---------------------+\n",
            "|                Embeddings                |    Model     |        # Params       | Bleu-Score | Mean-latency (in ms) | 90P-latency (in ms) | 99P-latency (in ms) |\n",
            "+------------------------------------------+--------------+-----------------------+------------+----------------------+---------------------+---------------------+\n",
            "| Glove word-embeddings(largest available) | LSTM Enc-dec | 9.2M {1.5M trainable} |    0.1     |        48.22         |        84.19        |        131.04       |\n",
            "|              Sentence-piece              |  T5 (Base)   |          220M         |    0.07    |        882.76        |       1364.36       |       2461.01       |\n",
            "|           Byte-Pair embeddings           | GPT-2 (Base) |          124M         |    0.18    |       11882.1        |       19693.22      |       21115.62      |\n",
            "+------------------------------------------+--------------+-----------------------+------------+----------------------+---------------------+---------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports, loading models and data"
      ],
      "metadata": {
        "id": "870pdlru-lS8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0E123AVwV8uC"
      },
      "outputs": [],
      "source": [
        "# import and load data\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import re\n",
        "import pickle\n",
        "import email\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "from dateutil import parser\n",
        "import nltk\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense,Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "\n",
        "import re\n",
        "!pip install --upgrade --no-cache-dir gdown\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load model and data"
      ],
      "metadata": {
        "id": "XhhLH59Nqayf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load gpt2 model\n",
        "gpt2.mount_gdrive()\n",
        "gpt2.copy_checkpoint_from_gdrive(run_name='run1')\n",
        "\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run1')"
      ],
      "metadata": {
        "id": "VWAq64b5hjPN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f99fb274-6ceb-461d-d7c6-3dcff90d91ed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Loading checkpoint checkpoint/run1/model-2500\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-2500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "!gdown --id 1cvJp9HTZ5z6FvMl5Q7bCenWVbtqgzYCa\n",
        "with open('Sequence_data.pickle', 'rb') as file:\n",
        "    train_sequences,test_sequences = pickle.load(file)\n",
        "\n",
        "train_sequences.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "qIrK69UxXnJu",
        "outputId": "37ee00dd-7aca-4553-bc40-81917f09d020"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cvJp9HTZ5z6FvMl5Q7bCenWVbtqgzYCa\n",
            "To: /content/Sequence_data.pickle\n",
            "100% 122M/122M [00:01<00:00, 117MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        enc_seq                          dec_seq\n",
              "0            I take back my dog                     comment john\n",
              "1    I take back my dog comment                             john\n",
              "2         Please take a look at  it You may find it useful Vince\n",
              "3      Please take a look at it     You may find it useful Vince\n",
              "4  Please take a look at it You         may find it useful Vince"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77f40d6f-3180-4f25-80da-62508940df8e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>enc_seq</th>\n",
              "      <th>dec_seq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I take back my dog</td>\n",
              "      <td>comment john</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I take back my dog comment</td>\n",
              "      <td>john</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Please take a look at</td>\n",
              "      <td>it You may find it useful Vince</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Please take a look at it</td>\n",
              "      <td>You may find it useful Vince</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Please take a look at it You</td>\n",
              "      <td>may find it useful Vince</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77f40d6f-3180-4f25-80da-62508940df8e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-77f40d6f-3180-4f25-80da-62508940df8e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-77f40d6f-3180-4f25-80da-62508940df8e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_gpt(s,l=30):\n",
        "    '''\n",
        "    Predict from fine-tuned GPT after prefixing \n",
        "    '''\n",
        "    prefix=\"<|startoftext|> \"+s\n",
        "    p = gpt2.generate(sess,\n",
        "                prefix=prefix,\n",
        "                truncate=\"<|endoftext|>\",\n",
        "                length=l,\n",
        "                run_name='run1',\n",
        "                temperature=0.7,\n",
        "                include_prefix=True,    \n",
        "                return_as_list=True\n",
        "                )[0]\n",
        "                \n",
        "    p = p[len(prefix):]\n",
        "    return p.strip()"
      ],
      "metadata": {
        "id": "jbPNBN97LDNp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Error analysis on predictions"
      ],
      "metadata": {
        "id": "4YuNTwEFZrVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_prediction_for_sample(data,k=10,seed=None):\n",
        "    '''\n",
        "    Randomly sample 'k' sentences and make predictions\n",
        "    '''\n",
        "    if seed:\n",
        "        np.random.seed(seed)\n",
        "    indices = np.random.choice(data.shape[0],size=k)\n",
        "    for idx in indices:\n",
        "        input_sentence = data.iloc[idx].enc_seq\n",
        "        target_sentence = data.iloc[idx].dec_seq\n",
        "        print(\"Input:\",input_sentence)\n",
        "        print('='*130)\n",
        "        print(\"Output:\",target_sentence)\n",
        "        print('='*130)\n",
        "        p = predict_gpt(input_sentence)\n",
        "        print(\"Prediction:\",p)\n",
        "        print()\n",
        "\n",
        "get_prediction_for_sample(test_sequences,seed=42)"
      ],
      "metadata": {
        "id": "5Z7mMgLCadDF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22054cd9-947c-46d3-c7dc-024e6088ec90"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Thanks for the update I will complete a review and send the worksheet up first thing in the morning Please let me know if that will be a problem\n",
            "==================================================================================================================================\n",
            "Output: d\n",
            "==================================================================================================================================\n",
            "Prediction: \n",
            "\n",
            "Input: Rob she could talk to about\n",
            "==================================================================================================================================\n",
            "Output: a position as a paralegal is looking for help on some of the asset work\n",
            "==================================================================================================================================\n",
            "Prediction: him being available for an interview How much do you think Brian\n",
            "\n",
            "Input: No I am actually pretty happy about the deal Not as happy as I would be\n",
            "==================================================================================================================================\n",
            "Output: if I were working for you\n",
            "==================================================================================================================================\n",
            "Prediction: if I were working for you\n",
            "\n",
            "Input: Vince Thanks for you offer I need to change\n",
            "==================================================================================================================================\n",
            "Output: my agenda for next week so would something in early July work for you Thanks for your assistance\n",
            "==================================================================================================================================\n",
            "Prediction: my itinerary to Friday Vince\n",
            "\n",
            "Input: HourAhead No ancillary schedules awarded No variances detected LOG\n",
            "==================================================================================================================================\n",
            "Output: PARSING FILE PortlandWestDeskCalifornia SchedulingISO Final Schedules txt\n",
            "==================================================================================================================================\n",
            "Prediction: PARSING FILE PortlandWestDeskCalifornia SchedulingISO Final txt retrieving HourAhead price data process continuing\n",
            "\n",
            "Input: This request has been pending your approval for days Please click to review and act upon this\n",
            "==================================================================================================================================\n",
            "Output: request ed For\n",
            "==================================================================================================================================\n",
            "Prediction: request ed For\n",
            "\n",
            "Input: please tell me that you did not move out and why did not you buy\n",
            "==================================================================================================================================\n",
            "Output: some this morning\n",
            "==================================================================================================================================\n",
            "Prediction: some this morning\n",
            "\n",
            "Input: im not i was on the phone\n",
            "==================================================================================================================================\n",
            "Output: with carolyn\n",
            "==================================================================================================================================\n",
            "Prediction: call\n",
            "\n",
            "Input: Well it looks close between our two fantasy football teams I will pull for your players tonight if you cheer\n",
            "==================================================================================================================================\n",
            "Output: for ours\n",
            "==================================================================================================================================\n",
            "Prediction: for ours\n",
            "\n",
            "Input: Attached is the final version of the Master Purchase Sale Agreement for let me know if you need\n",
            "==================================================================================================================================\n",
            "Output: anything else\n",
            "==================================================================================================================================\n",
            "Prediction: to amend Thank you Jennifer\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations :-    \n",
        "1) The Output predictions do not exactly match with our predictions (hence low bleu-score) which is not an issue tbh for our assisted-writing problem as we want our predictions to be general with some context-alignment with the prefix inputted to the model. If it is exactly equal to the output in most cases, then our model just memorized the Enron-data.   \n",
        "2) In the model's predictions we can see the model outputting names like - Jennifer, Kay etc. so it's better to have a filter/another NER-model on top of our model's prediction to not predict such personal-information. Same goes for abusive words (there are some instances of it in Enron data as well.)    \n",
        "3) There are some instances of overfitting/memorizing in the above examples, like when the output is :-     \n",
        "\" PARSING FILE PortlandWestDeskCalifornia SchedulingISO Final Schedules txt \"    \n",
        "and our model predicted exactly this.    \n",
        "To avoid this we can fix our preprocessing steps and remove emails with attachments, logs, automated-emails etc. But this will require a lot of manual effort as well.    \n",
        "Other than that, since our model's prediction is general and bleu-score on test set is quite good, our model hasn't overfitted."
      ],
      "metadata": {
        "id": "SZyxlZkZjWdr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# END"
      ],
      "metadata": {
        "id": "Ejtvpz3Q8Sir"
      }
    }
  ]
}